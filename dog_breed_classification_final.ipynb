{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64421fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from tensorflow.python.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88e87da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(X,Y):\n",
    "    \n",
    "    X_p = resnet50.preprocess_input(X)\n",
    "    Y_p = tf.keras.util.to_category(Y,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9833a114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf2713ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path, size):\n",
    "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (size, size))\n",
    "    image = image / 255.0\n",
    "    image = image.astype(np.float32)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21454f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(x, y):\n",
    "    x = x.decode()\n",
    "\n",
    "    num_class = 11\n",
    "    size = 224\n",
    "\n",
    "    image = read_image(x, size)\n",
    "    label = [0] * num_class\n",
    "    label[y] = 1\n",
    "    label = np.array(label)\n",
    "    label = label.astype(np.int32)\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b2f1d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_parse(x, y):\n",
    "    x, y = tf.numpy_function(parse_data, [x, y], [tf.float32, tf.int32])\n",
    "    x.set_shape((224, 224, 3))\n",
    "    y.set_shape((11))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d727b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_dataset(x, y, batch=8):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(tf_parse)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.repeat()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ba6862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = resnet50.ResNet50(weights='imagenet',include_top=False, input_shape=(224, 224, 3))\n",
    "# model.trainable = True\n",
    "# x = model.output\n",
    "# x = Flatten()(x)\n",
    "# x=Dropout(0.35)(x)\n",
    "# x=Dense(units=1000,activation='relu')(x)\n",
    "# x=Dropout(0.4)(x)\n",
    "# x=Dense(units=750,activation='relu')(x)\n",
    "# x=Dropout(0.4)(x)\n",
    "# x=Dense(units=1000,activation='relu')(x)\n",
    "# x=Dropout(0.8)(x)\n",
    "# #clf.add(Dense(units=120,activation='softmax')\n",
    "# #stochastic gradient descent -Adam -optimizer\n",
    "# #loss func categorical cross entropy\n",
    "# #metrics = accuracy\n",
    "# #clf.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# predictions = Dense(11, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e2eb774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def build_model(size, num_classes):\n",
    "    #inputs = tf.keras.Input(shape=(size, size, 3))\n",
    "    #backbone = resnet50.ResNet50(weights='imagnet',include_top=False, input_shape=(224, 224, 3)\n",
    "model = resnet50.ResNet50(weights='imagenet',include_top=False, input_shape=(224, 224, 3))\n",
    "model.trainable = True\n",
    "x = model.output\n",
    "#     print(backbone.summary)\n",
    "#     print(x.shape)\n",
    "#     x = GlobalAveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "#     x = Dense(1024, activation=\"relu\")(x)\n",
    "#     x = Dense(num_classes, activation=\"softmax\")(x)\n",
    "#    x = backbone.output\n",
    "#     x = Flatten()(x)\n",
    "x = Dropout(0.35)(x)\n",
    "x = Dense(units=1000,activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(units=750,activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(units=1000,activation='relu')(x)\n",
    "x = Dropout(0.8)(x)\n",
    "    #clf.add(Dense(units=120,activation='softmax')\n",
    "    #stochastic gradient descent -Adam -optimizer\n",
    "    #loss func categorical cross entropy\n",
    "    #metrics = accuracy\n",
    "    #clf.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "predictions = Dense(11, activation='softmax')(x)\n",
    "#model = Model(inputs, x)\n",
    "#return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70f752e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Total params: 125,453,473\n",
      "Trainable params: 101,865,761\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "main_model = Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "#train only the hidden layers and output layer, donot train the resnet model\n",
    "for curLayer in model.layers:\n",
    "    curLayer.trainable = False\n",
    "    \n",
    "main_model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]\n",
    "main_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3e80f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:\\DAG_BREED_CLASSIFICATION\\Dog-Breed-Classifier-using-TF2.0-master/\"\n",
    "train_path = os.path.join(path, \"train/*\")\n",
    "test_path = os.path.join(path, \"test/*\")\n",
    "labels_path = os.path.join(path, \"labels.csv\")\n",
    "#     ids = np.array(ids,dtype = 'float64')\n",
    "#     labels = np.array(labels)\n",
    "## Spliting the dataset\n",
    "#     train_x,train_y = pre_process_data(train_x,train_y)\n",
    "#     valid_x,valid_y = pre_process_data(valid_x,valid_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f1079f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Breed:  11\n"
     ]
    }
   ],
   "source": [
    "labels_df = pd.read_csv(labels_path)\n",
    "breed = labels_df[\"breed\"].unique()\n",
    "print(\"Number of Breed: \", len(breed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09ac4c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "breed2id = {name: i for i, name in enumerate(breed)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ecf4e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = glob(train_path)\n",
    "labels = []\n",
    "\n",
    "for image_id in ids:\n",
    "    image_id = image_id.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "    breed_name = np.array(labels_df[labels_df.id == image_id][\"breed\"])[0]\n",
    "    breed_idx = breed2id[breed_name]\n",
    "    labels.append(breed_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7b62a046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Other_breeds/Not_Defined'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58aa3df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = ids[:1000]\n",
    "labels = labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64511698",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x = train_test_split(ids, test_size=0.2, random_state=42)\n",
    "train_y, valid_y = train_test_split(labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c857a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 224\n",
    "num_classes = 11\n",
    "lr = 1e-4\n",
    "batch = 16\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9d88207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset shapes: ((None, 224, 224, 3), (None, 11)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf_dataset(train_x, train_y, batch=batch)\n",
    "valid_dataset = tf_dataset(valid_x, valid_y, batch=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75440cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(\"model.h5\", verbose=1, save_best_only=True),\n",
    "    ReduceLROnPlateau(factor=0.1, patience=5, min_lr=1e-4)\n",
    "]\n",
    "train_steps = (len(train_x)//batch) + 1\n",
    "valid_steps = (len(valid_x)//batch) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dee3545a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "51/51 [==============================] - 96s 2s/step - loss: 0.4650 - accuracy: 0.9093 - val_loss: 0.6271 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 2/25\n",
      "51/51 [==============================] - 97s 2s/step - loss: 0.4546 - accuracy: 0.9179 - val_loss: 0.5339 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 3/25\n",
      "51/51 [==============================] - 101s 2s/step - loss: 0.4412 - accuracy: 0.9179 - val_loss: 0.5011 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 4/25\n",
      "51/51 [==============================] - 101s 2s/step - loss: 0.4378 - accuracy: 0.9142 - val_loss: 0.4988 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 5/25\n",
      "51/51 [==============================] - 102s 2s/step - loss: 0.4140 - accuracy: 0.9203 - val_loss: 0.6357 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 6/25\n",
      "51/51 [==============================] - 101s 2s/step - loss: 0.4149 - accuracy: 0.9191 - val_loss: 0.7443 - val_accuracy: 0.9100\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 7/25\n",
      "51/51 [==============================] - 100s 2s/step - loss: 0.3936 - accuracy: 0.9203 - val_loss: 0.6460 - val_accuracy: 0.9000\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 8/25\n",
      "51/51 [==============================] - 102s 2s/step - loss: 0.3864 - accuracy: 0.9191 - val_loss: 0.6647 - val_accuracy: 0.8750\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 9/25\n",
      "51/51 [==============================] - 102s 2s/step - loss: 0.3819 - accuracy: 0.9265 - val_loss: 0.5724 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 10/25\n",
      "51/51 [==============================] - 100s 2s/step - loss: 0.3709 - accuracy: 0.9203 - val_loss: 0.5101 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 11/25\n",
      "51/51 [==============================] - 99s 2s/step - loss: 0.3622 - accuracy: 0.9216 - val_loss: 0.5208 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 12/25\n",
      "51/51 [==============================] - 102s 2s/step - loss: 0.3549 - accuracy: 0.9216 - val_loss: 0.5666 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 13/25\n",
      "51/51 [==============================] - 103s 2s/step - loss: 0.3512 - accuracy: 0.9228 - val_loss: 0.5745 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 14/25\n",
      "51/51 [==============================] - 103s 2s/step - loss: 0.3298 - accuracy: 0.9240 - val_loss: 0.6507 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 15/25\n",
      "51/51 [==============================] - 101s 2s/step - loss: 0.3409 - accuracy: 0.9216 - val_loss: 0.6983 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 16/25\n",
      "51/51 [==============================] - 99s 2s/step - loss: 0.3481 - accuracy: 0.9252 - val_loss: 0.8344 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 17/25\n",
      "51/51 [==============================] - 101s 2s/step - loss: 0.4094 - accuracy: 0.9167 - val_loss: 0.7810 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 18/25\n",
      "51/51 [==============================] - 99s 2s/step - loss: 0.3560 - accuracy: 0.9216 - val_loss: 0.6066 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 19/25\n",
      "51/51 [==============================] - 102s 2s/step - loss: 0.3315 - accuracy: 0.9265 - val_loss: 0.5632 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 20/25\n",
      "51/51 [==============================] - 99s 2s/step - loss: 0.3459 - accuracy: 0.9252 - val_loss: 0.5629 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 21/25\n",
      "51/51 [==============================] - 101s 2s/step - loss: 0.3407 - accuracy: 0.9252 - val_loss: 0.6189 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 22/25\n",
      "51/51 [==============================] - 101s 2s/step - loss: 0.3269 - accuracy: 0.9301 - val_loss: 0.5942 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 23/25\n",
      "51/51 [==============================] - 102s 2s/step - loss: 0.3224 - accuracy: 0.9289 - val_loss: 0.6016 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 24/25\n",
      "51/51 [==============================] - 102s 2s/step - loss: 0.3538 - accuracy: 0.9277 - val_loss: 0.5706 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "Epoch 25/25\n",
      "51/51 [==============================] - 101s 2s/step - loss: 0.3692 - accuracy: 0.9277 - val_loss: 0.5721 - val_accuracy: 0.9150\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26924e4be80>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch=train_steps,\n",
    "        epochs=25,\n",
    "        validation_data=valid_dataset,\n",
    "        validation_steps=valid_steps,\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e6015a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# test_set = []\n",
    "# test_set_ids = []\n",
    "# for curImage in os.listdir('E:\\\\DAG_BREED_CLASSIFICATION\\\\test'):\n",
    "#     test_set_ids.append(os.path.splitext(curImage)[0])\n",
    "# #     print(test_set_ids)\n",
    "# #     curImage = cv2.imread('E:\\\\DAG_BREED_CLASSIFICATION\\\\test/'+curImage)\n",
    "# #     #print(curImage)\n",
    "# #     #test_set.append(cv2.resize(curImage,(224,224)))\n",
    "#     test_data = \n",
    "    \n",
    "#\n",
    "# breed2id = {name: i for i, name in enumerate(breed)}\n",
    "# id2breed = {i: name for i, name in enumerate(breed)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a4324de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, path in tqdm(enumerate(valid_x[:10])):\n",
    "#     image = read_image(path, 224)\n",
    "#     image = np.expand_dims(image, axis=0)\n",
    "#     pred = model.predict(image)[0]\n",
    "#     label_idx = np.argmax(pred)\n",
    "#     breed_name = id2breed[label_idx]\n",
    "\n",
    "#     ori_breed = id2breed[valid_y[i]]\n",
    "#     ori_image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "\n",
    "#     ori_image = cv2.putText(ori_image, breed_name, (0, 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "#     ori_image = cv2.putText(ori_image, ori_breed, (0, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "\n",
    "#     cv2.imwrite(f\"save/valid_{i}.png\", ori_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef2b715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"E:\\DAG_BREED_CLASSIFICATION\"\n",
    "# train_path = os.path.join(path, \"train/*\")\n",
    "# test_path = os.path.join(path, \"test/*\")\n",
    "# labels_path = os.path.join(path, \"labels.csv\")\n",
    "\n",
    "# labels_df = pd.read_csv(labels_path)\n",
    "# breed = labels_df[\"breed\"].unique()\n",
    "# print(\"Number of Breed: \", len(breed))\n",
    "\n",
    "#breed2id = {name: i for i, name in enumerate(breed)}\n",
    "id2breed = {i: name for i, name in enumerate(breed)}\n",
    "\n",
    "# ids = glob(train_path)\n",
    "# labels = []\n",
    "\n",
    "# for image_id in ids:\n",
    "#     image_id = image_id.split(\"/\")[-1].split(\".\")[0]\n",
    "#     breed_name = list(labels_df[labels_df.id == image_id][\"breed\"])[0]\n",
    "#     breed_idx = breed2id[breed_name]\n",
    "#     labels.append(breed_idx)\n",
    "\n",
    "# ids = ids[:1000]\n",
    "# labels = labels[:1000]\n",
    "\n",
    "## Spliting the dataset\n",
    "# train_x, valid_x = train_test_split(ids, test_size=0.2, random_state=42)\n",
    "# train_y, valid_y = train_test_split(labels, test_size=0.2, random_state=42)\n",
    "\n",
    "## Model\n",
    "#model = tf.keras.models.load_model(\"model.h5\")\n",
    "# idstest = glob(test_path)\n",
    "# print(idstest)\n",
    "pred = []\n",
    "ori_breed = []\n",
    "ori_image = []\n",
    "for path in idstest:\n",
    "    image = read_image(path, 224)\n",
    "    image = np.expand_dims(image, axis=0)    \n",
    "    pred = main_model.predict(image)[0]\n",
    "    label_idx = np.argmax(pred)\n",
    "    breed_name = id2breed[label_idx]\n",
    "\n",
    "    ori_breed = id2breed[valid_y[i]]\n",
    "    ori_image = cv2.imread(path, cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b0e414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7c347e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
